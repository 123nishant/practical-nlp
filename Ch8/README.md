
# Social Media

Set of notebooks associated with Chapter 8 of the book

1. **[01_Create a wordcloud](https://github.com/practical-nlp/practical-nlp/blob/master/Ch8/WordCloud.ipynb)**: How to create a wordcloud. This is often used to get a quick sense of given text corpus at hand.

2. **[02_Effect of different tokenizers on Social Media Text Data](https://github.com/practical-nlp/practical-nlp/blob/master/Ch8/DifferentTokenizers.ipynb)** : Here we show how different tokenizers can give different output for the same input text. When dealing to text data from social platforms this can have huge bearing on the performance of the task.  Here, we will be working with 5 different tokenizers, namely:

    * [word_tokenize from NLTK](https://www.nltk.org/api/nltk.tokenize.html)
   * [TweetTokenizer from NLTK](https://www.nltk.org/api/nltk.tokenize.html)
   * [Twikenizer](https://pypi.org/project/twikenizer/)
   * [Twokenizer by ARK@CMU](http://www.cs.cmu.edu/~ark/TweetNLP/)
   * [twokenize](https://github.com/leondz/twokenize)
    

3. **[03_Trending topics](https://github.com/practical-nlp/practical-nlp/blob/master/Ch8/TrendingTopics.ipynb)**: Find trending topics on Twitter using tweepy

4. **[04_Sentiment Analysis](https://github.com/practical-nlp/practical-nlp/blob/master/Ch8/Textblob.ipynb)**: Basic sentiment analysis using TextBlob 

5. **[05_Preprocessing Social Media Text Data](https://github.com/practical-nlp/practical-nlp/blob/master/Ch8/smtd_preprocessing.py)**: Common steps involved in pre-processing pipeline for Social Media Text Data

6. **[06_Text representation of Social Media Text Data](https://github.com/practical-nlp/practical-nlp/blob/master/Ch8/SMTD_embeddings.ipynb)**: How to use embeddings to represent Social Media Text Data

8. **07_Sentiment Analysis**:  Here we use the preprocessing and representation steps learnt before to build a better classifier. 
